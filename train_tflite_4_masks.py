"""
Script de antrenare TFLite pentru segmentarea cartonaÈ™elor Hot Wheels
FoloseÈ™te cele 4 mÄƒÈ™ti existente (0.png, 11.png, 24.png, 33.png)

REQUIREMENTS:
- Python 3.8+
- tensorflow>=2.14.0
- numpy
- pillow (PIL)

INSTALARE:
py -m pip install tensorflow numpy pillow

FOLOSIRE:
1. OrganizeazÄƒ pozele È™i mÄƒÈ™tile:
   dataset/
     images/
       0.jpg
       11.jpg
       24.jpg
       33.jpg
     masks/
       0.png
       11.png
       24.png
       33.png

2. RuleazÄƒ: py train_tflite_4_masks.py

3. Modelul va fi salvat ca: card_segmentation.tflite
"""

import os
import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
import glob

print("=" * 60)
print("ğŸš€ Antrenare TFLite pentru 4 mÄƒÈ™ti")
print("=" * 60)

# ============================================================================
# CONFIGURARE
# ============================================================================
IMAGE_SIZE = 256  # Dimensiune input pentru model (256x256)
BATCH_SIZE = 2   # Batch size mic pentru 4 imagini
EPOCHS = 50       # NumÄƒr de epoci (poate fi ajustat)
VALIDATION_SPLIT = 0.2  # 20% pentru validare (1 imagine din 4)

# Path-uri - structura existentÄƒ dupÄƒ convert_coco_to_masks.py
CURRENT_DIR = os.getcwd()
IMAGES_DIR = os.path.join(CURRENT_DIR, "images")  # Pozele originale (0.jpg, 11.jpg, 24.jpg, 33.jpg)
MASKS_DIR = os.path.join(CURRENT_DIR, "masks")    # MÄƒÈ™tile (0.png, 11.png, 24.png, 33.png)
OUTPUT_MODEL = "card_segmentation.tflite"

# ============================================================================
# VERIFICARE DATE
# ============================================================================
print("\nğŸ“ Verificare dataset...")

# VerificÄƒ dacÄƒ existÄƒ folderul cu mÄƒÈ™ti
if not os.path.exists(MASKS_DIR):
    print(f"âŒ Folderul {MASKS_DIR} nu existÄƒ!")
    print("   AsigurÄƒ-te cÄƒ ai rulat convert_coco_to_masks.py È™i ai folderul 'masks'")
    print(f"   Folderul curent: {CURRENT_DIR}")
    exit(1)

# GÄƒseÈ™te toate imaginile È™i mÄƒÈ™tile
image_files = sorted(glob.glob(os.path.join(IMAGES_DIR, "*.jpg")))
mask_files = sorted(glob.glob(os.path.join(MASKS_DIR, "*.png")))

print(f"   Imagini gÄƒsite: {len(image_files)}")
print(f"   MÄƒÈ™ti gÄƒsite: {len(mask_files)}")

if len(image_files) == 0 or len(mask_files) == 0:
    print("âŒ Nu s-au gÄƒsit imagini sau mÄƒÈ™ti!")
    exit(1)

# VerificÄƒ cÄƒ fiecare imagine are o mascÄƒ corespunzÄƒtoare
matched_pairs = []
for img_path in image_files:
    img_name = os.path.basename(img_path).replace(".jpg", "")
    mask_path = os.path.join(MASKS_DIR, f"{img_name}.png")
    
    if os.path.exists(mask_path):
        matched_pairs.append((img_path, mask_path))
        print(f"   âœ… {img_name}.jpg â†” {img_name}.png")
    else:
        print(f"   âš ï¸  {img_name}.jpg - mascÄƒ lipsÄƒ!")

if len(matched_pairs) < 4:
    print(f"âŒ Doar {len(matched_pairs)} perechi gÄƒsite. NecesitÄƒm minim 4!")
    exit(1)

print(f"\nâœ… {len(matched_pairs)} perechi imagini-mÄƒÈ™ti gÄƒsite")

# ============================================================================
# ÃNCÄ‚RCARE DATE
# ============================================================================
print("\nğŸ“¥ ÃncÄƒrcare date...")

def load_image(path, target_size=(IMAGE_SIZE, IMAGE_SIZE)):
    """ÃncarcÄƒ È™i redimensioneazÄƒ imaginea"""
    img = Image.open(path).convert('RGB')
    img = img.resize(target_size, Image.Resampling.LANCZOS)
    img_array = np.array(img, dtype=np.float32) / 255.0  # NormalizeazÄƒ [0, 1]
    return img_array

def load_mask(path, target_size=(IMAGE_SIZE, IMAGE_SIZE)):
    """ÃncarcÄƒ È™i redimensioneazÄƒ masca (binarÄƒ)"""
    mask = Image.open(path).convert('L')  # Grayscale
    mask = mask.resize(target_size, Image.Resampling.NEAREST)
    mask_array = np.array(mask, dtype=np.float32)
    # NormalizeazÄƒ: > 128 = 1 (cartonaÈ™), <= 128 = 0 (background)
    mask_array = (mask_array > 128).astype(np.float32)
    return mask_array

# ÃncarcÄƒ toate perechile
images = []
masks = []

for img_path, mask_path in matched_pairs:
    img = load_image(img_path)
    mask = load_mask(mask_path)
    images.append(img)
    masks.append(mask)
    print(f"   âœ… {os.path.basename(img_path)} ({img.shape}) + {os.path.basename(mask_path)} ({mask.shape})")

images = np.array(images)
masks = np.array(masks)
masks = np.expand_dims(masks, axis=-1)  # AdaugÄƒ dimensiune channel: (4, 256, 256, 1)

print(f"\nâœ… Date Ã®ncÄƒrcate:")
print(f"   Images shape: {images.shape}")
print(f"   Masks shape: {masks.shape}")

# ============================================================================
# DATA AUGMENTATION (pentru a creÈ™te dataset-ul)
# ============================================================================
print("\nğŸ”„ Data augmentation (creÈ™te dataset-ul de la 4 la ~16 imagini)...")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Augmentare pentru imagini
img_datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=False,  # Nu flip-uim cartonaÈ™ele
    fill_mode='constant',
    cval=0.0
)

# Augmentare pentru mÄƒÈ™ti (aceleaÈ™i transformÄƒri)
mask_datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.1,
    horizontal_flip=False,
    fill_mode='constant',
    cval=0.0
)

# AplicÄƒ augmentarea
augmented_images = [images]
augmented_masks = [masks]

for i in range(3):  # 3x augmentare = 4 * 4 = 16 imagini total
    for img, mask in zip(images, masks):
        # GenereazÄƒ transformÄƒri identice pentru imagine È™i mascÄƒ
        seed = np.random.randint(10000)
        
        img_aug = img_datagen.random_transform(img, seed=seed)
        mask_aug = mask_datagen.random_transform(mask.squeeze(), seed=seed)
        mask_aug = np.expand_dims(mask_aug, axis=-1)
        
        augmented_images.append(np.expand_dims(img_aug, axis=0))
        augmented_masks.append(np.expand_dims(mask_aug, axis=0))

augmented_images = np.vstack(augmented_images)
augmented_masks = np.vstack(augmented_masks)

print(f"   âœ… Dataset augmentat: {augmented_images.shape[0]} imagini")

# ============================================================================
# SPLIT TRAIN/VALIDATION
# ============================================================================
from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(
    augmented_images, augmented_masks,
    test_size=0.2,
    random_state=42
)

print(f"\nğŸ“Š Split dataset:")
print(f"   Train: {X_train.shape[0]} imagini")
print(f"   Validation: {X_val.shape[0]} imagini")

# ============================================================================
# MODEL UNet SIMPLIFICAT
# ============================================================================
print("\nğŸ—ï¸  Construire model UNet...")

def build_unet(input_size=(IMAGE_SIZE, IMAGE_SIZE, 3)):
    """ConstruieÈ™te un model UNet simplificat pentru segmentare"""
    
    inputs = keras.Input(input_size)
    
    # Encoder
    c1 = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)
    c1 = layers.Conv2D(32, 3, activation='relu', padding='same')(c1)
    p1 = layers.MaxPooling2D((2, 2))(c1)
    
    c2 = layers.Conv2D(64, 3, activation='relu', padding='same')(p1)
    c2 = layers.Conv2D(64, 3, activation='relu', padding='same')(c2)
    p2 = layers.MaxPooling2D((2, 2))(c2)
    
    c3 = layers.Conv2D(128, 3, activation='relu', padding='same')(p2)
    c3 = layers.Conv2D(128, 3, activation='relu', padding='same')(c3)
    p3 = layers.MaxPooling2D((2, 2))(c3)
    
    # Bottleneck
    c4 = layers.Conv2D(256, 3, activation='relu', padding='same')(p3)
    c4 = layers.Conv2D(256, 3, activation='relu', padding='same')(c4)
    
    # Decoder
    u5 = layers.UpSampling2D((2, 2))(c4)
    u5 = layers.concatenate([u5, c3])
    c5 = layers.Conv2D(128, 3, activation='relu', padding='same')(u5)
    c5 = layers.Conv2D(128, 3, activation='relu', padding='same')(c5)
    
    u6 = layers.UpSampling2D((2, 2))(c5)
    u6 = layers.concatenate([u6, c2])
    c6 = layers.Conv2D(64, 3, activation='relu', padding='same')(u6)
    c6 = layers.Conv2D(64, 3, activation='relu', padding='same')(c6)
    
    u7 = layers.UpSampling2D((2, 2))(c6)
    u7 = layers.concatenate([u7, c1])
    c7 = layers.Conv2D(32, 3, activation='relu', padding='same')(u7)
    c7 = layers.Conv2D(32, 3, activation='relu', padding='same')(c7)
    
    # Output
    outputs = layers.Conv2D(1, 1, activation='sigmoid')(c7)
    
    model = keras.Model(inputs, outputs)
    return model

model = build_unet()
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='binary_crossentropy',
    metrics=['accuracy', 'binary_accuracy']
)

print(f"âœ… Model construit:")
model.summary()

# ============================================================================
# ANTRENARE
# ============================================================================
print("\nğŸ¯ Antrenare model...")
print(f"   Epochs: {EPOCHS}")
print(f"   Batch size: {BATCH_SIZE}")

callbacks = [
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
    ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)
]

history = model.fit(
    X_train, y_train,
    batch_size=BATCH_SIZE,
    epochs=EPOCHS,
    validation_data=(X_val, y_val),
    callbacks=callbacks,
    verbose=1
)

print("\nâœ… Antrenare completÄƒ!")

# ============================================================================
# CONVERSIE LA TFLite
# ============================================================================
print("\nğŸ”„ Conversie la TFLite...")

# ÃncarcÄƒ cel mai bun model
model.load_weights('best_model.h5')

# ConverteÈ™te la TFLite
converter = tf.lite.TFLiteConverter.from_keras_model(model)

# OptimizÄƒri pentru mÄƒrime È™i vitezÄƒ
converter.optimizations = [tf.lite.Optimize.DEFAULT]

# ConverteÈ™te
tflite_model = converter.convert()

# SalveazÄƒ
with open(OUTPUT_MODEL, 'wb') as f:
    f.write(tflite_model)

file_size = os.path.getsize(OUTPUT_MODEL) / (1024 * 1024)  # MB
print(f"âœ… Model TFLite salvat: {OUTPUT_MODEL}")
print(f"   MÄƒrime: {file_size:.2f} MB")

# ============================================================================
# TESTARE MODEL
# ============================================================================
print("\nğŸ§ª Testare model...")

# TesteazÄƒ pe o imagine de validare
test_img = X_val[0:1]
test_mask = y_val[0:1]

prediction = model.predict(test_img, verbose=0)
prediction_binary = (prediction > 0.5).astype(np.float32)

# CalculeazÄƒ IoU (Intersection over Union)
intersection = np.logical_and(test_mask, prediction_binary).sum()
union = np.logical_or(test_mask, prediction_binary).sum()
iou = intersection / union if union > 0 else 0

print(f"   IoU (Intersection over Union): {iou:.3f}")
print(f"   (1.0 = perfect, >0.7 = bun, >0.5 = acceptabil)")

# ============================================================================
# FINAL
# ============================================================================
print("\n" + "=" * 60)
print("âœ… GATA! Modelul TFLite este gata!")
print("=" * 60)
print(f"\nğŸ“¦ Model salvat: {OUTPUT_MODEL}")
print(f"   CopiazÄƒ-l Ã®n: app/src/main/assets/models/card_segmentation.tflite")
print("\nğŸ“ UrmÄƒtorii paÈ™i:")
print("   1. CopiazÄƒ card_segmentation.tflite Ã®n folderul models/ din Android")
print("   2. Rebuild aplicaÈ›ia")
print("   3. TesteazÄƒ - TFLite va fi folosit automat!")
print("\n" + "=" * 60)

